spark.sql.inMemoryColumnarStorage.compressed=true
spark.sql.inMemoryColumnarStorage.batchSize=10000
spark.sql.files.maxPartitionBytes=134217728
spark.sql.files.openCostInBytes=4194304
spark.sql.files.minPartitionNum=Default Parallelism
spark.sql.files.maxPartitionNum=None
spark.sql.broadcastTimeout=300
spark.sql.autoBroadcastJoinThreshold=10485760
spark.sql.shuffle.partitions=200
spark.sql.sources.parallelPartitionDiscovery.threshold=32
spark.sql.sources.parallelPartitionDiscovery.parallelism=10000
spark.sql.adaptive.coalescePartitions.enabled=true
spark.sql.adaptive.coalescePartitions.parallelismFirst=true
spark.sql.adaptive.coalescePartitions.minPartitionSize=1MB
spark.sql.adaptive.coalescePartitions.initialPartitionNum=(none)
spark.sql.adaptive.advisoryPartitionSizeInBytes=64MB
spark.sql.adaptive.optimizeSkewsInRebalancePartitions.enabled=true
spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor=0.2
spark.sql.adaptive.autoBroadcastJoinThreshold=(none)
spark.sql.adaptive.localShuffleReader.enabled=true
spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold=0
spark.sql.adaptive.skewJoin.enabled=true
spark.sql.adaptive.skewJoin.skewedPartitionFactor=5.0
spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes=256MB
spark.sql.adaptive.forceOptimizeSkewedJoin=false
spark.sql.adaptive.optimizer.excludedRules=(none)
spark.sql.adaptive.customCostEvaluatorClass=(none)